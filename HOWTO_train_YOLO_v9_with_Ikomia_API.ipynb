{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyGbD_GxAOI0"
      },
      "source": [
        "<img src='https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/banner_ikomia.png?raw=true'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKz9Zij7bN-t"
      },
      "source": [
        "# How to train YOLOv9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpxHrXhtbWTZ"
      },
      "source": [
        "## Overview of YOLOv9\n",
        "With the continuous evolution of computer vision technologies, YOLOv9 emerges as the latest advancement, developed by Chien-Yao Wang, I-Hau Yeh, and Hong-Yuan Mark Liao. This trio of researchers has a rich history in the field, having contributed to the development of preceding models such as YOLOv4, YOLOR, and YOLOv7.\n",
        "\n",
        "### ğŸŒ– Release\n",
        "\n",
        "YOLOv9 not only continues the legacy of its predecessors but also introduces significant innovations that set new benchmarks in object detection capabilities.\n",
        "\n",
        "\n",
        "YOLOv9 is an advanced object detection model that represents a significant leap forward in computer vision technology. It is the latest iteration in the \"You Only Look Once\" (YOLO) series, known for its high speed and accuracy in detecting objects in images.\n",
        "\n",
        "\n",
        "### ğŸŒ† Architecture and innovations:\n",
        "\n",
        "YOLOv9 stands out due to its incorporation of Programmable Gradient Information (PGI) and the introduction of the Generalized Efficient Layer Aggregation Network (GELAN), two groundbreaking innovations designed to enhance model performance and efficiency.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### :rocket: Accuracy and performance:\n",
        "\n",
        "| Model | Test Size | AP<sup>val</sup> | AP<sub>50</sub><sup>val</sup> | AP<sub>75</sub><sup>val</sup> | Param. | FLOPs |\n",
        "| :-- | :-: | :-: | :-: | :-: | :-: | :-: |\n",
        "| **YOLOv9-S** | 640 | **46.8%** | **63.4%** | **50.7%** | **7.2M** | **26.7G** |\n",
        "| **YOLOv9-M** | 640 | **51.4%** | **68.1%** | **56.1%** | **20.1M** | **76.8G** |\n",
        "| **YOLOv9-C** | 640 | **53.0%** | **70.2%** | **57.8%** | **25.5M** | **102.8G** |\n",
        "| **YOLOv9-E** | 640 | **55.6%** | **72.8%** | **60.6%** | **58.1M** | **192.5G** |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4CdI0J1ej5b"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5O31W412NRx"
      },
      "source": [
        "Please use a GPU for this tutorial.\n",
        "\n",
        "In the menu, select \"Runtime\" then \"Change runtime type\", choose GPU in \"Hardware accelerator\".\n",
        "\n",
        "Check your GPU with the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OJFMsi47Yrqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f0e248-0ddd-4e44-8db3-18e3d00b01f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 29 11:30:02 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBmJN2AaDmcI"
      },
      "source": [
        "First of all, you need to install Ikomia API pip package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8eSnQYJygrDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37d43161-3e8b-4128-baee-d9be230dd9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ikomia\n",
            "  Downloading ikomia-0.10.0-cp310-none-manylinux2014_x86_64.whl (148.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.4/148.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from ikomia) (3.0.10)\n",
            "Collecting setuptools==59.5.0 (from ikomia)\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<1.24,>=1.20.3 (from ikomia)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.28.0 in /usr/local/lib/python3.10/dist-packages (from ikomia) (2.31.0)\n",
            "Collecting mlflow==1.30.0 (from ikomia)\n",
            "  Downloading mlflow-1.30.0-py3-none-any.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard<3.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from ikomia) (2.15.2)\n",
            "Requirement already satisfied: Pillow>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from ikomia) (9.4.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from ikomia) (4.66.4)\n",
            "Requirement already satisfied: matplotlib<4.0,>=3.4.3 in /usr/local/lib/python3.10/dist-packages (from ikomia) (3.7.1)\n",
            "Collecting python-dotenv>=0.18.0 (from ikomia)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ikomia) (6.0.1)\n",
            "Collecting semver<4.0,>=3.0.1 (from ikomia)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==1.30.0->ikomia) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.10/dist-packages (from mlflow==1.30.0->ikomia) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow==1.30.0->ikomia) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==1.30.0->ikomia) (3.20.3)\n",
            "Collecting pytz<2023 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<22 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata!=4.7.0,<6,>=3.7.0 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==1.30.0->ikomia) (0.5.0)\n",
            "Collecting alembic<2 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<3 in /usr/local/lib/python3.10/dist-packages (from mlflow==1.30.0->ikomia) (2.2.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow==1.30.0->ikomia) (1.11.4)\n",
            "Collecting pandas<2 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prometheus-flask-exporter<1 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading prometheus_flask_exporter-0.23.0-py3-none-any.whl (18 kB)\n",
            "Collecting querystring-parser<2 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting sqlalchemy<2,>=1.4.0 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading SQLAlchemy-1.4.52-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gunicorn<21 (from mlflow==1.30.0->ikomia)\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.28.0->ikomia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.28.0->ikomia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.28.0->ikomia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.28.0->ikomia) (2024.2.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (1.64.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (3.6)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (3.0.3)\n",
            "Collecting Mako (from alembic<2->mlflow==1.30.0->ikomia)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic<2->mlflow==1.30.0->ikomia) (4.11.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==1.30.0->ikomia) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==1.30.0->ikomia) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==1.30.0->ikomia) (0.9.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow==1.30.0->ikomia) (1.8.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow==1.30.0->ikomia) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow==1.30.0->ikomia) (2.2.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow==1.30.0->ikomia)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3.0,>=2.5.0->ikomia) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3.0,>=2.5.0->ikomia) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3.0,>=2.5.0->ikomia) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3.0,>=2.5.0->ikomia) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow==1.30.0->ikomia) (3.18.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from prometheus-flask-exporter<1->mlflow==1.30.0->ikomia) (0.20.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow==1.30.0->ikomia) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<3.0,>=2.5.0->ikomia) (2.1.5)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==1.30.0->ikomia)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3.0,>=2.5.0->ikomia) (0.6.0)\n",
            "Installing collected packages: pytz, sqlalchemy, smmap, setuptools, semver, querystring-parser, python-dotenv, packaging, numpy, Mako, importlib-metadata, pandas, gunicorn, gitdb, docker, databricks-cli, alembic, prometheus-flask-exporter, gitpython, mlflow, ikomia\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.4\n",
            "    Uninstalling pytz-2023.4:\n",
            "      Successfully uninstalled pytz-2023.4\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.30\n",
            "    Uninstalling SQLAlchemy-2.0.30:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.30\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cvxpy 1.3.4 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.52 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.1 databricks-cli-0.18.0 docker-6.1.3 gitdb-4.0.11 gitpython-3.1.43 gunicorn-20.1.0 ikomia-0.10.0 importlib-metadata-5.2.0 mlflow-1.30.0 numpy-1.23.5 packaging-21.3 pandas-1.5.3 prometheus-flask-exporter-0.23.0 python-dotenv-1.0.1 pytz-2022.7.1 querystring-parser-1.2.4 semver-3.0.2 setuptools-59.5.0 smmap-5.0.1 sqlalchemy-1.4.52\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "numpy",
                  "packaging",
                  "pkg_resources",
                  "setuptools"
                ]
              },
              "id": "2c7e29861b1c406188ee8e63253da585"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install ikomia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktbA-VPOATgP"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**-Google Colab ONLY- Restart runtime**\n",
        "\n",
        "Click on the \"RESTART RUNTIME\" button at the end the previous window.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hS1T6ky1Wcw"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJsRFzl9Au1c"
      },
      "source": [
        "Ikomia API has already more than 300 pre-integrated algorithms but the most interesting algorithms are in [Ikomia HUB](https://github.com/Ikomia-hub).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgGi5tjosC8g"
      },
      "source": [
        "## How to train YOLOv9 on a custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwJit3k190PN"
      },
      "source": [
        "Download your dataset from your preferred tool. In this example, we use a dataset from **Roboflow** which is a great annotation platform used by many developers and companies. The dataset is exported in COCO format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RpGiTWgeRnIq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "# Download the file\n",
        "url = \"https://app.roboflow.com/ds/j1BEJld3NB?key=2PardK2OTb\"\n",
        "response = requests.get(url, stream=True)\n",
        "with open(\"roboflow.zip\", \"wb\") as file:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(\"roboflow.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Remove the zip file\n",
        "os.remove(\"roboflow.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgYm8QNx-ekO"
      },
      "source": [
        "In order to train YOLOv9 on your custom dataset, please create a new workflow from scratch.\n",
        "\n",
        "Then you need 2 components:\n",
        "\n",
        "1.   A COCO dataset loader which loads dataset in COCO format and convert it to an Ikomia format\n",
        "2.   The YOLOv9 training algorithm which loads dataset in Ikomia format\n",
        "\n",
        "Add these 2 previous algorithms to your workflow and then it will automagically download all algorithms from Ikomia Hub and install all the Python dependencies (the 1st time, it can take a while, be patient ! )."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1BKL7hpw15Z"
      },
      "source": [
        "Now, it's time to train your model !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AW06ne0oBNtK",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8ed04b66c0c94b08bb33f926a6acddf1",
            "eb6d83a557b742f1a6d0f528549f8bf6",
            "18829c703f094b2f8bcff1a045f4e096",
            "d884ababd54e44d684117b1254e4ffcf",
            "e7fb6d50e2c341098cb0181b440dda59",
            "14fd474137ea427a984ae49e45dda358",
            "18d037d625514c8c8b091c5874059761",
            "a7aa6f6925504e8ebe63c0d89e65eac9",
            "7d06f5db597a40238f543e39a3f15d9b",
            "e89e7e3a8a344cbb9f4dac67ce31248a",
            "edbb5f81656346618f2dc9aa182f67a7"
          ]
        },
        "outputId": "56fa6d23-1769-40b9-e739-6352311b1d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ikomia auto-completion updated for installed plugins.\n",
            "Ikomia auto-completion updated for Ikomia HUB algorithms.\n",
            "Try installing dataset_coco from Ikomia HUB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "dataset_coco.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.5k/19.5k [00:00<00:00, 15.5MiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dataset_coco requirements. This may take a while, please be patient...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
            "  setattr(self, word, getattr(machar, word).flat[0])\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
            "  return self._float_to_str(self.smallest_subnormal)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
            "  setattr(self, word, getattr(machar, word).flat[0])\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
            "  return self._float_to_str(self.smallest_subnormal)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ikomia auto-completion updated for installed plugins.\n",
            "Ikomia auto-completion updated for Ikomia HUB algorithms.\n",
            "Try installing train_yolo_v9 from Ikomia HUB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_yolo_v9.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 380M/380M [00:24<00:00, 16.5MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing train_yolo_v9 requirements. This may take a while, please be patient...\n",
            "Starting MLflow server...\n",
            "MLflow server started successfully at http://localhost:5000\n",
            "MLflow dashboard won't be accessible. You need to install pyngrok before starting your training workflow: !pip install pyngrok. You also need a free ngrok account at least.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MLflow dashboard won't be accessible. You need to install pyngrok before starting your training workflow: !pip install pyngrok. You also need a free ngrok account at least.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To enable Tensorboard on Colab, please use the magic command: %load_ext tensorboard\n",
            "Starting MLflow server...\n",
            "MLflow server started successfully at http://localhost:5000\n",
            "MLflow dashboard won't be accessible. You need to install pyngrok before starting your training workflow: !pip install pyngrok. You also need a free ngrok account at least.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MLflow dashboard won't be accessible. You need to install pyngrok before starting your training workflow: !pip install pyngrok. You also need a free ngrok account at least.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To enable Tensorboard on Colab, please use the magic command: %load_ext tensorboard\n",
            "Ikomia auto-completion updated for installed plugins.\n",
            "Ikomia auto-completion updated for Ikomia HUB algorithms.\n",
            "Starting MLflow server...\n",
            "MLflow server started successfully at http://localhost:5000\n",
            "MLflow dashboard won't be accessible. You need to install pyngrok before starting your training workflow: !pip install pyngrok. You also need a free ngrok account at least.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MLflow dashboard won't be accessible. You need to install pyngrok before starting your training workflow: !pip install pyngrok. You also need a free ngrok account at least.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To enable Tensorboard on Colab, please use the magic command: %load_ext tensorboard\n",
            "Preparing dataset...\n",
            "Collecting configuration parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=4, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7baa97b01cc0>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=3, connect=3, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7baa97b02b30>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=2, read=5, redirect=5, status=5)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7baa97b00f40>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/create\n",
            "\u001b[34m\u001b[1mtrain_yolo_v9_process: \u001b[0mweights=/root/Ikomia/Plugins/Python/train_yolo_v9/models/yolov9-c.pt, cfg=/root/Ikomia/Plugins/Python/train_yolo_v9/yolov9/models/detect/yolov9-c.yaml, data=/root/Ikomia/Plugins/Python/train_yolo_v9/dataset/dataset.yaml, hyp=/root/Ikomia/Plugins/Python/train_yolo_v9/yolov9/data/hyps/hyp.scratch-high.yaml, epochs=50, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content, name=29-05-2024T11h38m00s, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, nc=80, depth_multiple=1.0, width_multiple=1.0, anchors=3, backbone=[[-1, 1, 'Silence', []], [-1, 1, 'Conv', [64, 3, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 1, 'RepNCSPELAN4', [256, 128, 64, 1]], [-1, 1, 'ADown', [256]], [-1, 1, 'RepNCSPELAN4', [512, 256, 128, 1]], [-1, 1, 'ADown', [512]], [-1, 1, 'RepNCSPELAN4', [512, 512, 256, 1]], [-1, 1, 'ADown', [512]], [-1, 1, 'RepNCSPELAN4', [512, 512, 256, 1]]], head=[[-1, 1, 'SPPELAN', [512, 256]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 7], 1, 'Concat', [1]], [-1, 1, 'RepNCSPELAN4', [512, 512, 256, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 5], 1, 'Concat', [1]], [-1, 1, 'RepNCSPELAN4', [256, 256, 128, 1]], [-1, 1, 'ADown', [256]], [[-1, 13], 1, 'Concat', [1]], [-1, 1, 'RepNCSPELAN4', [512, 512, 256, 1]], [-1, 1, 'ADown', [512]], [[-1, 10], 1, 'Concat', [1]], [-1, 1, 'RepNCSPELAN4', [512, 512, 256, 1]], [5, 1, 'CBLinear', [[256]]], [7, 1, 'CBLinear', [[256, 512]]], [9, 1, 'CBLinear', [[256, 512, 512]]], [0, 1, 'Conv', [64, 3, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 1, 'RepNCSPELAN4', [256, 128, 64, 1]], [-1, 1, 'ADown', [256]], [[23, 24, 25, -1], 1, 'CBFuse', [[0, 0, 0]]], [-1, 1, 'RepNCSPELAN4', [512, 256, 128, 1]], [-1, 1, 'ADown', [512]], [[24, 25, -1], 1, 'CBFuse', [[1, 1]]], [-1, 1, 'RepNCSPELAN4', [512, 512, 256, 1]], [-1, 1, 'ADown', [512]], [[25, -1], 1, 'CBFuse', [[2]]], [-1, 1, 'RepNCSPELAN4', [512, 512, 256, 1]], [[31, 34, 37, 16, 19, 22], 1, 'DualDDetect', ['nc']]], img_size=[640, 640], tb_dir=/root/Ikomia/Tensorboard/29-05-2024T11h38m00s, stop_train=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ 2024-5-29 Python-3.10.12 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, dfl=1.5, obj_pw=1.0, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/755k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ed04b66c0c94b08bb33f926a6acddf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1         0  train_yolo_v9.yolov9.models.common.Silence[]                            \n",
            "  1                -1  1      1856  train_yolo_v9.yolov9.models.common.Conv [3, 64, 3, 2]                 \n",
            "  2                -1  1     73984  train_yolo_v9.yolov9.models.common.Conv [64, 128, 3, 2]               \n",
            "  3                -1  1    212864  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[128, 256, 128, 64, 1]        \n",
            "  4                -1  1    164352  train_yolo_v9.yolov9.models.common.ADown[256, 256]                    \n",
            "  5                -1  1    847616  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[256, 512, 256, 128, 1]       \n",
            "  6                -1  1    656384  train_yolo_v9.yolov9.models.common.ADown[512, 512]                    \n",
            "  7                -1  1   2857472  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[512, 512, 512, 256, 1]       \n",
            "  8                -1  1    656384  train_yolo_v9.yolov9.models.common.ADown[512, 512]                    \n",
            "  9                -1  1   2857472  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[512, 512, 512, 256, 1]       \n",
            " 10                -1  1    656896  train_yolo_v9.yolov9.models.common.SPPELAN[512, 512, 256]               \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 7]  1         0  train_yolo_v9.yolov9.models.common.Concat[1]                           \n",
            " 13                -1  1   3119616  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[1024, 512, 512, 256, 1]      \n",
            " 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 15           [-1, 5]  1         0  train_yolo_v9.yolov9.models.common.Concat[1]                           \n",
            " 16                -1  1    912640  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[1024, 256, 256, 128, 1]      \n",
            " 17                -1  1    164352  train_yolo_v9.yolov9.models.common.ADown[256, 256]                    \n",
            " 18          [-1, 13]  1         0  train_yolo_v9.yolov9.models.common.Concat[1]                           \n",
            " 19                -1  1   2988544  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[768, 512, 512, 256, 1]       \n",
            " 20                -1  1    656384  train_yolo_v9.yolov9.models.common.ADown[512, 512]                    \n",
            " 21          [-1, 10]  1         0  train_yolo_v9.yolov9.models.common.Concat[1]                           \n",
            " 22                -1  1   3119616  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[1024, 512, 512, 256, 1]      \n",
            " 23                 5  1    131328  train_yolo_v9.yolov9.models.common.CBLinear[512, [256]]                  \n",
            " 24                 7  1    393984  train_yolo_v9.yolov9.models.common.CBLinear[512, [256, 512]]             \n",
            " 25                 9  1    656640  train_yolo_v9.yolov9.models.common.CBLinear[512, [256, 512, 512]]        \n",
            " 26                 0  1      1856  train_yolo_v9.yolov9.models.common.Conv [3, 64, 3, 2]                 \n",
            " 27                -1  1     73984  train_yolo_v9.yolov9.models.common.Conv [64, 128, 3, 2]               \n",
            " 28                -1  1    212864  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[128, 256, 128, 64, 1]        \n",
            " 29                -1  1    164352  train_yolo_v9.yolov9.models.common.ADown[256, 256]                    \n",
            " 30  [23, 24, 25, -1]  1         0  train_yolo_v9.yolov9.models.common.CBFuse[[0, 0, 0]]                   \n",
            " 31                -1  1    847616  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[256, 512, 256, 128, 1]       \n",
            " 32                -1  1    656384  train_yolo_v9.yolov9.models.common.ADown[512, 512]                    \n",
            " 33      [24, 25, -1]  1         0  train_yolo_v9.yolov9.models.common.CBFuse[[1, 1]]                      \n",
            " 34                -1  1   2857472  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[512, 512, 512, 256, 1]       \n",
            " 35                -1  1    656384  train_yolo_v9.yolov9.models.common.ADown[512, 512]                    \n",
            " 36          [25, -1]  1         0  train_yolo_v9.yolov9.models.common.CBFuse[[2]]                         \n",
            " 37                -1  1   2857472  train_yolo_v9.yolov9.models.common.RepNCSPELAN4[512, 512, 512, 256, 1]       \n",
            " 38[31, 34, 37, 16, 19, 22]  1  21556682  train_yolo_v9.yolov9.models.yolo.DualDDetect[7, [512, 512, 512, 256, 512, 512]]\n",
            "yolov9-c summary: 962 layers, 51013450 parameters, 51013418 gradients, 238.9 GFLOPs\n",
            "\n",
            "Transferred 1448/1460 items from /root/Ikomia/Plugins/Python/train_yolo_v9/models/yolov9-c.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 238 weight(decay=0.0), 255 weight(decay=0.0005), 253 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/Ikomia/Plugins/Python/train_yolo_v9/dataset/labels/train... 42 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 00:00\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /root/Ikomia/Plugins/Python/train_yolo_v9/dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/Ikomia/Plugins/Python/train_yolo_v9/dataset/labels/val... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 00:00\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /root/Ikomia/Plugins/Python/train_yolo_v9/dataset/labels/val.cache\n",
            "Plotting labels to /content/29-05-2024T11h38m00s/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/29-05-2024T11h38m00s\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       0/49      9.74G       2.06       4.99      2.227         67        640:   0%|          | 0/6 00:04WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n",
            "       0/49      10.3G      2.216      5.445      2.011         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:15\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:01\n",
            "                   all         10         48      0.221      0.134     0.0861     0.0626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/49      10.3G      2.022      5.131      2.016         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48     0.0242      0.342     0.0345     0.0187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/49      10.3G      1.897      5.047      2.072         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48     0.0762     0.0712     0.0439     0.0249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/49      10.3G      1.789       4.62      1.895         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48     0.0712      0.097     0.0726       0.05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/49      10.3G      1.745      4.362      1.917         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.246      0.203     0.0907     0.0681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/49      10.3G      1.746      3.719      1.902         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.329      0.166       0.16      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/49      10.3G      1.505      3.447      1.617         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.149      0.282      0.204      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/49      10.3G      1.439      3.518        1.8          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.182      0.317      0.214      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/49      10.6G      1.406      3.041      1.628         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.163      0.384       0.19      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/49      10.6G      1.432      3.179      1.836         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.218      0.296      0.282      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/49      10.6G      1.448      3.134      1.719          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.199      0.466      0.271      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/49      10.6G      1.543      3.783      1.744          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.263      0.424      0.245      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/49      10.6G      1.358      2.946      1.571         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.211      0.471      0.253      0.208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/49      10.6G      1.292      2.644      1.619         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.362      0.398       0.22       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/49      10.6G       1.23      2.715      1.447         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.362      0.398       0.22       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/49      10.6G      1.507      2.816      1.723         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48       0.48      0.259      0.251      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/49      10.6G      1.408      3.026      1.632         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.626      0.264      0.263      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/49      10.6G      1.395      2.763      1.645         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.464      0.204      0.131      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/49      10.6G      1.285      2.722      1.602          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.464      0.204      0.131      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/49      10.6G      1.581      3.644      1.718          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.108      0.239      0.107     0.0863\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/49      10.6G      1.248      2.859      1.518         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.259      0.174      0.122     0.0981\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/49      10.6G      1.348      2.794      1.588         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.436      0.208      0.178      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/49      10.6G      1.329      2.625      1.563         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.436      0.208      0.178      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/49      10.6G      1.205      2.596      1.532          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.544      0.238      0.194      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/49      10.6G      1.378      2.492      1.554         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.384      0.215      0.175      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/49      10.6G      1.215      2.463      1.481         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.543      0.298      0.272      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/49      10.6G      1.277      2.324      1.556          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.543      0.298      0.272      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/49      10.6G      1.164        2.3      1.479          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48       0.64      0.247      0.261      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/49      10.6G      1.443       2.71      1.807          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.634      0.233      0.236      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/49      10.6G      1.278       2.02      1.557          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.442      0.253       0.22      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/49      10.6G       1.24      2.189      1.485         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.442      0.253       0.22      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/49      10.6G      1.331      2.185      1.541         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.255      0.352      0.221      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/49      10.6G      1.267      2.066      1.407         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.263      0.378      0.249      0.195\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/49      10.6G      1.283      2.064      1.626         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.271      0.479       0.26      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/49      10.6G      1.237      1.909      1.501         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.271      0.479       0.26      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/49      10.6G      1.214       2.34      1.589          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.211      0.457      0.256      0.219\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/49      10.6G      1.221      1.826      1.481         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.206      0.331      0.256      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/49      10.6G      1.116      1.958      1.496         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.282      0.287      0.254      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/49      10.6G      1.087      1.967      1.439          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.282      0.287      0.254      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/49      10.6G      1.376      2.023      1.572         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.257      0.413      0.265      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/49      10.6G      1.146      1.909      1.459         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.226      0.388      0.264      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/49      10.6G      1.206      2.026      1.518         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.243       0.42       0.25      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/49      10.6G      1.287      2.002      1.612         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.243       0.42       0.25      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/49      10.6G      1.189      1.932      1.461         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.202      0.299      0.228      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/49      10.6G      1.261      1.946      1.521         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.223      0.378      0.242      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/49      10.6G      1.211      1.876      1.469         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.251      0.424      0.259      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/49      10.9G      1.187      1.696      1.412         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.251      0.424      0.259      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/49      10.9G      1.225      1.698       1.44         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.213      0.395      0.257        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/49      11.1G      1.201      1.692      1.428         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:04\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.303      0.329      0.273      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/49      11.1G      1.072       1.68      1.397         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 00:05\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.345      0.317      0.273      0.217\n",
            "\n",
            "50 epochs completed in 0.116 hours.\n",
            "Optimizer stripped from /content/29-05-2024T11h38m00s/weights/last.pt, 102.8MB\n",
            "Optimizer stripped from /content/29-05-2024T11h38m00s/weights/best.pt, 102.8MB\n",
            "\n",
            "Validating /content/29-05-2024T11h38m00s/weights/best.pt...\n",
            "Fusing layers... \n",
            "yolov9-c summary: 724 layers, 50972490 parameters, 0 gradients, 237.7 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 00:00\n",
            "                   all         10         48      0.218      0.296      0.282      0.226\n",
            "- weapon_detect - 2024-05-26 10-35am         10         10          0          0     0.0874     0.0426\n",
            "    License- CC BY 4.0         10          2          0          0     0.0391     0.0352\n",
            "Provided by a Roboflow user         10          8      0.423        0.5      0.533      0.392\n",
            "https-universe.roboflow.com-rapidev-pmcmr-image-labelling-uhngw         10         10      0.565        0.6      0.558      0.473\n",
            "https-universe.roboflow.com-weapondetect-weapon_detect-g5exr         10          5      0.113        0.6      0.294      0.267\n",
            "             undefined         10         13       0.21     0.0769      0.182      0.148\n",
            "Results saved to \u001b[1m/content/29-05-2024T11h38m00s\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow Untitled run successfully in 465235.220138 ms.\n"
          ]
        }
      ],
      "source": [
        "from ikomia.dataprocess.workflow import Workflow\n",
        "import os\n",
        "\n",
        "#----------------------------- Step 1 -----------------------------------#\n",
        "# Create a workflow which will take your dataset as input and\n",
        "# train a YOLOv9 model on it\n",
        "#------------------------------------------------------------------------#\n",
        "wf = Workflow()\n",
        "\n",
        "#----------------------------- Step 2 -----------------------------------#\n",
        "# First you need to convert the COCO format to IKOMIA format.\n",
        "# Add an Ikomia dataset converter to your workflow.\n",
        "#------------------------------------------------------------------------#\n",
        "\n",
        "dataset = wf.add_task(name = \"dataset_coco\")\n",
        "\n",
        "dataset.set_parameters({\n",
        "    \"json_file\": os.getcwd()+\"/train/_annotations.coco.json\",\n",
        "    \"image_folder\": os.getcwd()+\"/train\",\n",
        "    \"task\":\"detection\",\n",
        "    \"output_folder\": os.getcwd()+\"/dataset\"\n",
        "})\n",
        "\n",
        "\n",
        "#----------------------------- Step 3 -----------------------------------#\n",
        "# Then, you want to train a YOLOv9 model.\n",
        "# Add YOLOv9 training algorithm to your workflow\n",
        "#------------------------------------------------------------------------#\n",
        "\n",
        "train = wf.add_task(name=\"train_yolo_v9\", auto_connect=True)\n",
        "train.set_parameters({\n",
        "    \"model_name\": \"yolov9-c\",\n",
        "    \"epochs\": \"50\",\n",
        "    \"batch_size\": \"8\",\n",
        "    \"train_imgsz\": \"640\",\n",
        "    \"test_imgsz\": \"640\",\n",
        "    \"dataset_split_ratio\": \"0.8\",\n",
        "    \"output_folder\": os.getcwd(),\n",
        "})\n",
        "\n",
        "\n",
        "#----------------------------- Step 4 -----------------------------------#\n",
        "# Execute your workflow.\n",
        "# It automatically runs all your tasks sequentially.\n",
        "#------------------------------------------------------------------------#\n",
        "wf.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGOI8k7PLDkb",
        "outputId": "f6bac689-229c-40cd-bdb2-9f85d314464c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpsaQoYSwma8"
      },
      "source": [
        "## Infer YOLOv9 object detection on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H2JCp2SOD2a"
      },
      "source": [
        "Once the training is finished, you may want to experiment the fresh model on new test images. Just use the following code to create a YOLO v8 instance\n",
        "segmentation inference workflow.\n",
        "Then run and test !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVH02tztrM4F",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set the output folder name\n",
        "TIMESTAMP = # \"27-02-2024T09h27m06s\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecT5qPDywrEi",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from ikomia.dataprocess.workflow import Workflow\n",
        "\n",
        "# Create your workflow for YOLO inference\n",
        "wf = Workflow()\n",
        "\n",
        "# Add YOLOv9 to your workflow\n",
        "yolov9 = wf.add_task(name=\"infer_yolo_v9\", auto_connect=True)\n",
        "\n",
        "yolov9.set_parameters({\n",
        "    \"model_weight_file\": os.getcwd()+ f'/{TIMESTAMP}/weights/best.pt',\n",
        "    \"class_file\": os.getcwd()+ f'/{TIMESTAMP}/classes.yaml',\n",
        "    \"conf_thres\": \"0.2\",\n",
        "    \"iou_thres\":\"0.25\",\n",
        "    \"input_size\":\"640\"\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKPnRdUj6Vq8"
      },
      "source": [
        "## Run and display your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdXFRaDi6Vq8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from ikomia.utils.displayIO import display\n",
        "from PIL import ImageShow\n",
        "ImageShow.register(ImageShow.IPythonViewer(), 0)\n",
        "\n",
        "# Apply YOLOv9 object detection on your image\n",
        "# By default, YOLOv9 runs with a pre-trained model based on COCO\n",
        "# To use your custom model, set the parameters in the previous cell\n",
        "\n",
        "wf.run_on(url=\"https://pbs.twimg.com/ext_tw_video_thumb/1660454979298115585/pu/img/A_Jrl2uawkkDi_Kf.jpg\")\n",
        "# wf.run_on(path=os.getcwd()+\"/test/youtube-128_jpg.rf.2723e31eec77e1ff7b73c45c625082f6.jpg\")\n",
        "\n",
        "# Get YOLOv9 image result\n",
        "img_bbox = yolov9.get_image_with_graphics()\n",
        "\n",
        "# Display in Colab\n",
        "display(img_bbox)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF5CAKdBrM4F"
      },
      "source": [
        "## Run on video\n",
        "\n",
        "This will work on local only, not on google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0F-qSDsrM4G"
      },
      "outputs": [],
      "source": [
        "from ikomia.dataprocess.workflow import Workflow\n",
        "from ikomia.utils.displayIO import display\n",
        "import cv2\n",
        "\n",
        "\n",
        "video_path = 'Path/to/your/video.mp4' # Example: https://www.youtube.com/watch?v=EAR5jTknVOw\n",
        "output_path = 'output.mp4'\n",
        "# Init your workflow\n",
        "wf = Workflow()\n",
        "\n",
        "# Add object detection algorithm\n",
        "detector = wf.add_task(name=\"infer_yolo_v9\", auto_connect=True)\n",
        "\n",
        "detector.set_parameters({\n",
        "    \"model_weight_file\": os.getcwd()+ f'/{TIMESTAMP}/weights/best.pt',\n",
        "    \"class_file\": os.getcwd()+ f'/{TIMESTAMP}/classes.yaml',\n",
        "    \"conf_thres\": \"0.2\",\n",
        "    \"iou_thres\":\"0.25\"\n",
        "})\n",
        "\n",
        "# Open the video file\n",
        "stream = cv2.VideoCapture(video_path)\n",
        "if not stream.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties for the output\n",
        "frame_width = int(stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frame_rate = stream.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "# The 'XVID' codec is widely supported and provides good quality\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(output_path, fourcc, frame_rate, (frame_width, frame_height))\n",
        "\n",
        "while True:\n",
        "    # Read image from stream\n",
        "    ret, frame = stream.read()\n",
        "\n",
        "    # Test if the video has ended or there is an error\n",
        "    if not ret:\n",
        "        print(\"Info: End of video or error.\")\n",
        "        break\n",
        "\n",
        "    # Run the workflow on current frame\n",
        "    wf.run_on(array=frame)\n",
        "\n",
        "    # Get results\n",
        "    image_out = detector.get_output(0)\n",
        "    obj_detect_out = detector.get_output(1)\n",
        "\n",
        "    # Convert the result to BGR color space for displaying\n",
        "    img_out = image_out.get_image_with_mask_and_graphics(obj_detect_out)\n",
        "    img_res = cv2.cvtColor(img_out, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Save the resulting frame\n",
        "    out.write(img_out)\n",
        "\n",
        "    # Display\n",
        "    display(img_res, title=\"YOLOv9 object detection\", viewer=\"opencv\")\n",
        "\n",
        "    # Press 'q' to quit the video processing\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# After the loop release everything\n",
        "stream.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "environment": {
      "kernel": "venvsd1",
      "name": "common-gpu.m114",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-gpu:m114"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8ed04b66c0c94b08bb33f926a6acddf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb6d83a557b742f1a6d0f528549f8bf6",
              "IPY_MODEL_18829c703f094b2f8bcff1a045f4e096",
              "IPY_MODEL_d884ababd54e44d684117b1254e4ffcf"
            ],
            "layout": "IPY_MODEL_e7fb6d50e2c341098cb0181b440dda59"
          }
        },
        "eb6d83a557b742f1a6d0f528549f8bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14fd474137ea427a984ae49e45dda358",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_18d037d625514c8c8b091c5874059761",
            "value": "100%"
          }
        },
        "18829c703f094b2f8bcff1a045f4e096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7aa6f6925504e8ebe63c0d89e65eac9",
            "max": 773236,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d06f5db597a40238f543e39a3f15d9b",
            "value": 773236
          }
        },
        "d884ababd54e44d684117b1254e4ffcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e89e7e3a8a344cbb9f4dac67ce31248a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_edbb5f81656346618f2dc9aa182f67a7",
            "value": "â€‡755k/755kâ€‡[00:00&lt;00:00,â€‡32.2MB/s]"
          }
        },
        "e7fb6d50e2c341098cb0181b440dda59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14fd474137ea427a984ae49e45dda358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d037d625514c8c8b091c5874059761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7aa6f6925504e8ebe63c0d89e65eac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d06f5db597a40238f543e39a3f15d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e89e7e3a8a344cbb9f4dac67ce31248a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edbb5f81656346618f2dc9aa182f67a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}